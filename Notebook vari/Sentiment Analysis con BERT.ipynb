{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCeCv0ivywnKx9zZB4j/os"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"c4MJruGWqVCb"},"outputs":[],"source":["#Sentiment Analysis con BERT\n","\n","from transformers import AutoTokenizer\n","\n","model = \"prajjwal1/bert-tiny\"\n","tokenizer = AutoTokenizer.from_pretrained(model, model_max_length=512)\n","\n","def preprocessing_function(examples):\n","   return tokenizer(examples['text'], truncation=True)\n","\n","from datasets import load_dataset\n","imdb = load_dataset(\"imdb\")\n","\n","\n","small_tr = tokenized_imdb['train'].select(range(7500))\n","small_ts = tokenized_imdb['test'].select(range(5000))\n","\n","\n","from transformers import DataCollatorWithPadding\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n","\n","\n","DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path=\"prajjwal1/bert-tiny\",\n","    vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right',\n","    truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]',\n","    'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'},\n","    clean_up_tokenization_spaces=True), padding=True, max_length=None,\n","    pad_to_multiple_of=None, return_tensors=\"tf\")\n","\n","\n","from transformers import TFAutoModelForSequenceClassification\n","\n","\n","id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n","\n","tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n","    \"prajjwal1/bert-tiny\", num_labels=2, id2label=id2label,\n","    label2id=label2id, from_pt=True\n",")\n","\n","\n","tf_train_set = tf_model.prepare_tf_dataset(\n","    small_tr,\n","    shuffle = True,\n","    batch_size=32,\n","    collate_fn = data_collator\n",")\n","\n","tf_validation_set = tf_model.prepare_tf_dataset(\n","    small_ts,\n","    shuffle = False,\n","    batch_size=32,\n","    collate_fn = data_collator\n",")\n","\n","\n","\n","tf_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5))\n","\n","import numpy as np\n","import evaluate\n","accuracy = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)\n","\n","from transformers.keras_callbacks import KerasMetricCallback\n","metric_callback = KerasMetricCallback(metric_fn = compute_metrics, eval_dataset = tf_validation_set)\n","\n","tf_model.fit(x = tf_train_set, validation_data = tf_validation_set, epochs = 3, callbacks = [metric_callback])\n","\n","tf_model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=metric_callback)\n","\n","\n","\n","from transformers import TextClassificationPipeline\n","text = \"I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood.\"\n","classifier = TextClassificationPipeline(tokenizer=tokenizer, model=tf_model, return_all_scores=True)\n","classifier(text)\n","\n"]}]}